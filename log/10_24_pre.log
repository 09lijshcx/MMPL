nohup: ignoring input
Random seed : 10
Pre-trained weights of KPGT were loaded successfully!
Set of Optimizer: lr:5e-05, weight_decay:1e-06
Current Optimizer is adan
Current learning rate is [3.333333333333334e-09].
Let's start training!
epoch: 1 / 15,step 999 / 18630, loss: 2.77281570
epoch: 1 / 15,step 1999 / 18630, loss: 2.77259874
epoch: 1 / 15,step 2999 / 18630, loss: 2.77259064
epoch: 1 / 15,step 3999 / 18630, loss: 2.77258945
epoch: 1 / 15,step 4999 / 18630, loss: 2.77259731
epoch: 1 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 1 / 15,step 6999 / 18630, loss: 2.77258897
epoch: 1 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 1 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 1 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 1 / 15,step 10999 / 18630, loss: 2.77258897
epoch: 1 / 15,step 11999 / 18630, loss: 2.77258921
epoch: 1 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 1 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 1 / 15,step 14999 / 18630, loss: 2.77258921
epoch: 1 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 1 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 1 / 15,step 17999 / 18630, loss: 2.77258873
epoch: 1 end ; cost time: 46.8174 min
Current learning rate is [4.9362995196491235e-05].
epoch: 2 / 15,step 999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 2999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 3999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 4999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 2 / 15,step 6999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 7999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 2 / 15,step 9999 / 18630, loss: 2.77258921
epoch: 2 / 15,step 10999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 11999 / 18630, loss: 2.77258921
epoch: 2 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 2 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 2 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 2 / 15,step 15999 / 18630, loss: 2.77258873
epoch: 2 / 15,step 16999 / 18630, loss: 2.77258921
epoch: 2 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 2 end ; cost time: 47.0210 min
Current learning rate is [4.6094639512280706e-05].
epoch: 3 / 15,step 999 / 18630, loss: 2.77258873
epoch: 3 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 2999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 3999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 4999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 6999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 7999 / 18630, loss: 2.77258873
epoch: 3 / 15,step 8999 / 18630, loss: 2.77258921
epoch: 3 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 3 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 3 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 13999 / 18630, loss: 2.77258873
epoch: 3 / 15,step 14999 / 18630, loss: 2.77258921
epoch: 3 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 3 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 3 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 3 end ; cost time: 46.9683 min
Current learning rate is [4.282628382807018e-05].
epoch: 4 / 15,step 999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 1999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 6999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 4 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 9999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 4 / 15,step 11999 / 18630, loss: 2.77258873
epoch: 4 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 4 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 16999 / 18630, loss: 2.77258897
epoch: 4 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 4 end ; cost time: 47.0787 min
Current learning rate is [3.955792814385965e-05].
epoch: 5 / 15,step 999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 1999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 2999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 4999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 6999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 7999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 9999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 10999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 11999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 13999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 14999 / 18630, loss: 2.77258873
epoch: 5 / 15,step 15999 / 18630, loss: 2.77258921
epoch: 5 / 15,step 16999 / 18630, loss: 2.77258897
epoch: 5 / 15,step 17999 / 18630, loss: 2.77258873
epoch: 5 end ; cost time: 46.8722 min
Current learning rate is [3.628957245964912e-05].
epoch: 6 / 15,step 999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 1999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 3999 / 18630, loss: 2.77258897
epoch: 6 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 6 / 15,step 7999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 6 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 6 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 6 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 13999 / 18630, loss: 2.77258897
epoch: 6 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 6 / 15,step 15999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 6 / 15,step 17999 / 18630, loss: 2.77258873
epoch: 6 end ; cost time: 46.8845 min
Current learning rate is [3.30212167754386e-05].
epoch: 7 / 15,step 999 / 18630, loss: 2.77258873
epoch: 7 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 7 / 15,step 2999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 3999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 4999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 5999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 6999 / 18630, loss: 2.77258897
epoch: 7 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 8999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 9999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 10999 / 18630, loss: 2.77258897
epoch: 7 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 7 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 7 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 14999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 15999 / 18630, loss: 2.77258921
epoch: 7 / 15,step 16999 / 18630, loss: 2.77258897
epoch: 7 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 7 end ; cost time: 46.9542 min
Current learning rate is [2.9752861091228072e-05].
epoch: 8 / 15,step 999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 3999 / 18630, loss: 2.77258921
epoch: 8 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 6999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 7999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 9999 / 18630, loss: 2.77258921
epoch: 8 / 15,step 10999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 11999 / 18630, loss: 2.77258921
epoch: 8 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 13999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 14999 / 18630, loss: 2.77258873
epoch: 8 / 15,step 15999 / 18630, loss: 2.77258921
epoch: 8 / 15,step 16999 / 18630, loss: 2.77258897
epoch: 8 / 15,step 17999 / 18630, loss: 2.77258921
epoch: 8 end ; cost time: 46.8701 min
Current learning rate is [2.6484505407017543e-05].
epoch: 9 / 15,step 999 / 18630, loss: 2.77258897
epoch: 9 / 15,step 1999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 2999 / 18630, loss: 2.77258897
epoch: 9 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 7999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 11999 / 18630, loss: 2.77258873
epoch: 9 / 15,step 12999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 9 / 15,step 15999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 16999 / 18630, loss: 2.77258921
epoch: 9 / 15,step 17999 / 18630, loss: 2.77258921
epoch: 9 end ; cost time: 46.9893 min
Current learning rate is [2.3216149722807014e-05].
epoch: 10 / 15,step 999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 1999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 3999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 10 / 15,step 7999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 9999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 10999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 10 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 13999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 14999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 15999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 10 / 15,step 17999 / 18630, loss: 2.77258921
epoch: 10 end ; cost time: 46.7981 min
Current learning rate is [1.9947794038596492e-05].
epoch: 11 / 15,step 999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 1999 / 18630, loss: 2.77258921
epoch: 11 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 5999 / 18630, loss: 2.77258921
epoch: 11 / 15,step 6999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 11 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 9999 / 18630, loss: 2.77258897
epoch: 11 / 15,step 10999 / 18630, loss: 2.77258897
epoch: 11 / 15,step 11999 / 18630, loss: 2.77258921
epoch: 11 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 11 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 11 / 15,step 15999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 11 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 11 end ; cost time: 46.9491 min
Current learning rate is [1.6679438354385963e-05].
epoch: 12 / 15,step 999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 1999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 2999 / 18630, loss: 2.77258897
epoch: 12 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 12 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 8999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 11999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 12 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 12 / 15,step 14999 / 18630, loss: 2.77258897
epoch: 12 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 12 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 12 / 15,step 17999 / 18630, loss: 2.77258897
epoch: 12 end ; cost time: 46.7371 min
Current learning rate is [1.3411082670175441e-05].
epoch: 13 / 15,step 999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 2999 / 18630, loss: 2.77258921
epoch: 13 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 5999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 6999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 7999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 13 / 15,step 11999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 12999 / 18630, loss: 2.77258921
epoch: 13 / 15,step 13999 / 18630, loss: 2.77258897
epoch: 13 / 15,step 14999 / 18630, loss: 2.77258921
epoch: 13 / 15,step 15999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 13 / 15,step 17999 / 18630, loss: 2.77258873
epoch: 13 end ; cost time: 46.9087 min
Current learning rate is [1.014272698596491e-05].
epoch: 14 / 15,step 999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 1999 / 18630, loss: 2.77258921
epoch: 14 / 15,step 2999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 3999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 4999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 5999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 14 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 14 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 9999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 14 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 12999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 13999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 14999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 14 / 15,step 16999 / 18630, loss: 2.77258873
epoch: 14 / 15,step 17999 / 18630, loss: 2.77258921
epoch: 14 end ; cost time: 46.9521 min
Current learning rate is [6.874371301754387e-06].
epoch: 15 / 15,step 999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 1999 / 18630, loss: 2.77258897
epoch: 15 / 15,step 2999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 3999 / 18630, loss: 2.77258873
epoch: 15 / 15,step 4999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 5999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 6999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 7999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 8999 / 18630, loss: 2.77258897
epoch: 15 / 15,step 9999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 10999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 11999 / 18630, loss: 2.77258897
epoch: 15 / 15,step 12999 / 18630, loss: 2.77258873
epoch: 15 / 15,step 13999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 14999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 15999 / 18630, loss: 2.77258897
epoch: 15 / 15,step 16999 / 18630, loss: 2.77258921
epoch: 15 / 15,step 17999 / 18630, loss: 2.77258873
epoch: 15 end ; cost time: 46.9062 min
Current learning rate is [3.6060156175438588e-06].
