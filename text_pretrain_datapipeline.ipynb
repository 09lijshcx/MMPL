{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f607ccb7-8700-4e0c-b17d-39b2479fbe71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libcusparse.so.11: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedSampler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/site-packages/dgl/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Backend and logging should be imported before other modules.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_verbose_logging  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_name, load_backend  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     container,\n\u001b[1;32m     18\u001b[0m     cuda,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     storages,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, DGLError\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/site-packages/dgl/backend/__init__.py:122\u001b[0m\n\u001b[1;32m    118\u001b[0m         set_default_backend(default_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 122\u001b[0m \u001b[43mload_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_preferred_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_enabled\u001b[39m(api):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return true if the api is enabled by the current backend.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        True if the API is enabled by the current backend.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/site-packages/dgl/backend/__init__.py:51\u001b[0m, in \u001b[0;36mload_backend\u001b[0;34m(mod_name)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m mod_name)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tensor_adapter  \u001b[38;5;66;03m# imports DGL C library\u001b[39;00m\n\u001b[1;32m     53\u001b[0m version \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m     54\u001b[0m load_tensor_adapter(mod_name, version)\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/site-packages/dgl/_ffi/base.py:50\u001b[0m\n\u001b[1;32m     48\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m libinfo\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# library instance of nnvm\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m _LIB, _LIB_NAME, _DIR_NAME \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# The FFI mode of DGL\u001b[39;00m\n\u001b[1;32m     53\u001b[0m _FFI_MODE \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDGL_FFI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/site-packages/dgl/_ffi/base.py:39\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load libary by searching possible path.\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m lib_path \u001b[38;5;241m=\u001b[39m libinfo\u001b[38;5;241m.\u001b[39mfind_lib_path()\n\u001b[0;32m---> 39\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m dirname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(lib_path[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     41\u001b[0m basename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_path[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/ctypes/__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libcusparse.so.11: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import torch\n",
    "# import dgl.backend as F\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from KPGT.src.data.featurizer import Vocab, N_BOND_TYPES, N_ATOM_TYPES\n",
    "from KPGT.src.data.collator_text import Collator_pretrain\n",
    "from KPGT.src.model.light import LiGhTPredictor as LiGhT\n",
    "from KPGT.src.trainer.scheduler import PolynomialDecayLR\n",
    "from KPGT.src.trainer.pretrain_trainer import Trainer\n",
    "# from KPGT.src.trainer.evaluator import Evaluator\n",
    "# from KPGT.src.trainer.result_tracker import Result_Tracker\n",
    "from KPGT.src.model_config import config_dict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# local_rank = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "class PubChemDataset(InMemoryDataset):\n",
    "    def __init__(self, path):\n",
    "        super(PubChemDataset, self).__init__()\n",
    "        self.data, self.slices = torch.load(path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get(idx)\n",
    "    \n",
    "smi_list = []\n",
    "text_list = []\n",
    "dataset = PubChemDataset('./pretrain_data/PubChem324kV2/pretrain.pt')\n",
    "for i in range(len(dataset)):\n",
    "    smi = dataset[i]['smiles']\n",
    "    smi_list.append(smi)\n",
    "    tex = dataset[i]['text']\n",
    "    text_list.append(tex)\n",
    "\n",
    "\n",
    "from CLIP import clip\n",
    "class MoleculeTextDataset(Dataset):\n",
    "    def __init__(self, smi_list, text_list):\n",
    "        # smiles_path = os.path.join(root_path, \"smiles.smi\")\n",
    "        # fp_path = os.path.join(root_path, \"rdkfp1-7_512.npz\")\n",
    "        # md_path = os.path.join(root_path, \"molecular_descriptors.npz\")\n",
    "        fp_path = \"/home/jovyan/prompts_learning/pretrain_data/rdkfp1-7_512.npz\"\n",
    "        md_path = \"/home/jovyan/prompts_learning/pretrain_data/molecular_descriptors.npz\"\n",
    "        # with open(smiles_path, 'r') as f:\n",
    "        #     lines = f.readlines()\n",
    "        #     self.smiles_list = [line.strip('\\n') for line in lines]\n",
    "        self.fps = torch.from_numpy(sps.load_npz(fp_path).todense().astype(np.float32))\n",
    "        mds = np.load(md_path)['md'].astype(np.float32)\n",
    "        mds = np.where(np.isnan(mds), 0, mds)\n",
    "        self.mds = torch.from_numpy(mds)\n",
    "        self.d_fps = self.fps.shape[1]\n",
    "        self.d_mds = self.mds.shape[1]        \n",
    "        \n",
    "        self.smiles_list = smi_list\n",
    "        self.text_list = text_list\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.smiles_list[idx], self.fps[idx], self.mds[idx], clip.tokenize(self.text_list[idx], truncate=True)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    config = config_dict['base']\n",
    "    print(config)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # torch.cuda.set_device(local_rank)\n",
    "    # torch.distributed.init_process_group(backend='nccl')\n",
    "    # device = torch.device('cuda', local_rank)\n",
    "    # set_random_seed(args.seed)\n",
    "    # print(local_rank)\n",
    "    \n",
    "    vocab = Vocab(N_ATOM_TYPES, N_BOND_TYPES)\n",
    "    collator = Collator_pretrain(vocab, max_length=config['path_length'], n_virtual_nodes=2, candi_rate=config['candi_rate'], fp_disturb_rate=config['fp_disturb_rate'], md_disturb_rate=config['md_disturb_rate'])\n",
    "    train_dataset = MoleculeTextDataset(smi_list, text_list)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=config['batch_size']// 1, num_workers=16, drop_last=True, collate_fn=collator)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, num_workers=16, drop_last=True, collate_fn=collator)\n",
    "    model = LiGhT(\n",
    "        d_node_feats=config['d_node_feats'],\n",
    "        d_edge_feats=config['d_edge_feats'],\n",
    "        d_g_feats=config['d_g_feats'],\n",
    "        d_fp_feats=train_dataset.d_fps,\n",
    "        d_md_feats=train_dataset.d_mds,\n",
    "        d_hpath_ratio=config['d_hpath_ratio'],\n",
    "        n_mol_layers=config['n_mol_layers'],\n",
    "        path_length=config['path_length'],\n",
    "        n_heads=config['n_heads'],\n",
    "        n_ffn_dense_layers=config['n_ffn_dense_layers'],\n",
    "        input_drop=config['input_drop'],\n",
    "        attn_drop=config['attn_drop'],\n",
    "        feat_drop=config['feat_drop'],\n",
    "        n_node_types=vocab.vocab_size\n",
    "    ).to(\"cuda\")\n",
    "    # model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank, find_unused_parameters=True)\n",
    "    model.load_state_dict({k.replace('module.', ''): v for k, v in torch.load(\"/home/jovyan/prompts_learning/KPGT/src/models/base.pth\").items()})\n",
    "    \n",
    "    device = \"cuda\"\n",
    "    for b_id, batched_data in enumerate(train_loader):\n",
    "        (smiles, batched_graph, fps, mds, sl_labels, disturbed_fps, disturbed_mds, text) = batched_data\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        fps = fps.to(device)\n",
    "        mds = mds.to(device)\n",
    "\n",
    "        mol_fps_feat = model.generate_fps(batched_graph, fps, mds)\n",
    "        break\n",
    "        \n",
    "    \n",
    "    print(\"okk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47820bec-b13c-454c-adab-c5bb85a02643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd7e9e8-1ea8-4d24-a6f9-4a42e66cb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc421136-e9d0-47d8-bd55-87096f100886",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LOCAL_RANK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m local_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLOCAL_RANK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(local_rank)\n",
      "File \u001b[0;32m~/.conda/fcb/lib/python3.8/os.py:675\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    672\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LOCAL_RANK'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "local_rank = int(os.environ['LOCAL_RANK'])\n",
    "print(local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64032d70-b195-43d6-8d5f-cda5d535f7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcb",
   "language": "python",
   "name": "fcb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
